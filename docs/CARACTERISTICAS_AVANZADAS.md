# üöÄ Caracter√≠sticas Avanzadas - Proyecto J

## üìã √çndice

1. [Sistema As√≠ncrono](#-sistema-as√≠ncrono)
2. [Logging JSON](#-logging-json)
3. [Manejo de Errores](#-manejo-de-errores)
4. [Pipeline Modular](#-pipeline-modular)
5. [Validaci√≥n de Datos](#-validaci√≥n-de-datos)
6. [Consultas en Lenguaje Natural](#-consultas-en-lenguaje-natural)
7. [An√°lisis de Tendencias](#-an√°lisis-de-tendencias)

---

## ‚ö° Sistema As√≠ncrono

### Estado Actual
- **C√≥digo base implementado:** `scripts/tasks.py` y `proyecto_j/utils/run_async_system.py`
- **Dependencias:** Redis, Celery
- **Configuraci√≥n requerida:** Configuraci√≥n manual por el usuario

### Instalaci√≥n
```bash
# Instalar dependencias as√≠ncronas
pip install -r scripts/requirements_async.txt

# Iniciar Redis (requerido)
# Windows: Descargar Redis desde https://redis.io/download
# Linux/Mac: brew install redis && redis-server
# Docker: docker run -d -p 6379:6379 redis:alpine

# Verificar sistema
python proyecto_j/utils/run_async_system.py --check

# Iniciar worker
python proyecto_j/utils/run_async_system.py --worker

# Iniciar aplicaci√≥n
python proyecto_j/utils/run_async_system.py --app
```

### Caracter√≠sticas
- Procesamiento paralelo de archivos grandes
- Monitoreo en tiempo real
- Cola de tareas con prioridades
- Recuperaci√≥n autom√°tica de errores
- M√©tricas de rendimiento

---

## üìù Logging JSON

### Ubicaci√≥n
- **Archivo principal:** `processing/json_logging.py`
- **Logs generados:** `logs/`
- **Formato:** JSON estructurado

### Estructura de Logs
```json
{
    "timestamp": "2024-01-15T10:30:00",
    "level": "INFO",
    "module": "pipeline_encuestas",
    "function": "procesar_encuesta",
    "message": "Encuesta procesada exitosamente",
    "data": {
        "filas_procesadas": 1500,
        "columnas_validadas": 25,
        "tiempo_procesamiento": 2.5
    },
    "session_id": "session_123",
    "tags": ["encuesta", "procesamiento"]
}
```

### Integraci√≥n con Herramientas
- **ELK Stack:** Importar logs desde `logs/pipeline.json`
- **Grafana:** Configurar fuente de datos JSON
- **Datadog:** Env√≠o autom√°tico de m√©tricas
- **Prometheus:** Exportaci√≥n de m√©tricas

---

## ‚ö†Ô∏è Manejo de Errores

### Sistema de Errores de Negocio
- **Archivo:** `processing/business_error_handler.py`
- **Categorizaci√≥n autom√°tica** de errores
- **Visualizaci√≥n en Streamlit** de errores
- **Exportaci√≥n de reportes** de errores

### Tipos de Errores Manejados
1. **Errores de Validaci√≥n** - Datos inconsistentes
2. **Errores de Procesamiento** - Fallos en transformaciones
3. **Errores de Configuraci√≥n** - Par√°metros incorrectos
4. **Errores de Sistema** - Problemas de recursos

### Recuperaci√≥n Autom√°tica
- Reintentos autom√°ticos para errores transitorios
- Rollback de operaciones fallidas
- Notificaciones de errores cr√≠ticos
- Logs detallados para debugging

---

## üîÑ Pipeline Modular

### Arquitectura
```
Pipeline
‚îú‚îÄ‚îÄ Carga de Datos
‚îú‚îÄ‚îÄ Validaci√≥n
‚îú‚îÄ‚îÄ Limpieza
‚îú‚îÄ‚îÄ Transformaci√≥n
‚îú‚îÄ‚îÄ An√°lisis
‚îú‚îÄ‚îÄ Visualizaci√≥n
‚îî‚îÄ‚îÄ Reporte
```

### Configuraci√≥n
```yaml
# config/config.yml
pipeline:
  steps:
    - name: "carga_datos"
      enabled: true
      parameters:
        encoding: "utf-8"
        delimiter: ","
    
    - name: "validacion"
      enabled: true
      parameters:
        strict_mode: false
    
    - name: "limpieza"
      enabled: true
      parameters:
        remove_duplicates: true
        fill_missing: "mean"
```

### Extensibilidad
- Agregar nuevos pasos f√°cilmente
- Configuraci√≥n por YAML/JSON
- Testing unitario por m√≥dulo
- Reutilizaci√≥n de componentes

---

## ‚úÖ Validaci√≥n de Datos

### Validadores Implementados
- **`data_validators.py`** - Validadores gen√©ricos
- **`validacion_chile.py`** - Validaci√≥n espec√≠fica para Chile
- **`validation_decorators.py`** - Decoradores de validaci√≥n

### Tipos de Validaci√≥n
1. **Validaci√≥n de Tipos** - Verificar tipos de datos
2. **Validaci√≥n de Rango** - Valores dentro de l√≠mites
3. **Validaci√≥n de Formato** - Patrones espec√≠ficos
4. **Validaci√≥n de Consistencia** - Relaciones entre campos
5. **Validaci√≥n Geogr√°fica** - C√≥digos de regi√≥n/comuna

### Ejemplo de Uso
```python
from processing.data_validators import validate_dataframe
from proyecto_j.src.validacion_chile import validar_datos_chile

# Validaci√≥n gen√©rica
result = validate_dataframe(df, schema)

# Validaci√≥n espec√≠fica Chile
result = validar_datos_chile(df)
```

---

## üß† Consultas en Lenguaje Natural

### M√≥dulos
- **`nl_query.py`** - Consultas b√°sicas
- **`nl_query_trends.py`** - An√°lisis de tendencias
- **`complex_grouping.py`** - Agrupaciones complejas

### Capacidades
- Procesamiento de preguntas en espa√±ol
- An√°lisis autom√°tico de patrones
- Generaci√≥n de visualizaciones sugeridas
- Exportaci√≥n de resultados

### Ejemplos de Consultas
```
"¬øCu√°l es la tendencia de ventas por regi√≥n?"
"Agrupa los datos por edad y g√©nero"
"Encuentra correlaciones entre variables"
"Muestra la distribuci√≥n de ingresos"
```

---

## üìà An√°lisis de Tendencias

### Caracter√≠sticas
- Detecci√≥n autom√°tica de patrones temporales
- An√°lisis de estacionalidad
- Predicci√≥n de tendencias
- Visualizaci√≥n de series temporales

### Algoritmos Implementados
- **STL (Seasonal and Trend decomposition)**
- **An√°lisis de autocorrelaci√≥n**
- **Suavizado exponencial**
- **Regresi√≥n temporal**

### Uso
```python
from proyecto_j.src.nl_query_trends import analizar_tendencias

# An√°lisis autom√°tico
result = analizar_tendencias(df, columna_tiempo, columna_valor)

# Visualizaci√≥n
result.plot_trends()
result.export_results()
```

---

## üîß Configuraci√≥n Avanzada

### Variables de Entorno
```bash
# Configuraci√≥n de logging
PROYECTO_J_LOG_LEVEL=INFO
PROYECTO_J_LOG_FORMAT=json
PROYECTO_J_LOG_FILE=logs/pipeline.log

# Configuraci√≥n de Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Configuraci√≥n de Celery
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
```

### Configuraci√≥n de Rendimiento
```yaml
# config/performance.yml
processing:
  max_workers: 4
  chunk_size: 1000
  memory_limit: "2GB"
  
caching:
  enabled: true
  ttl: 3600
  max_size: 1000
```

---

## üß™ Testing Avanzado

### Tipos de Tests
1. **Tests Unitarios** - Funciones individuales
2. **Tests de Integraci√≥n** - M√≥dulos completos
3. **Tests E2E** - Flujos completos
4. **Tests de Rendimiento** - M√©tricas de velocidad

### Ejecuci√≥n
```bash
# Tests con cobertura
pytest --cov=proyecto_j --cov-report=html tests/

# Tests de rendimiento
pytest tests/test_performance.py

# Tests de integraci√≥n
pytest tests/e2e/
```

---

## üìä Monitoreo y M√©tricas

### M√©tricas Disponibles
- **Tiempo de procesamiento** por paso
- **Uso de memoria** y CPU
- **Tasa de √©xito** de operaciones
- **Errores** por tipo y frecuencia
- **Rendimiento** de consultas

### Dashboards
- **Grafana** - M√©tricas en tiempo real
- **Kibana** - An√°lisis de logs
- **Streamlit** - Dashboard integrado

---

## üîÆ Roadmap

### Pr√≥ximas Caracter√≠sticas
1. **API REST** - Endpoints para integraci√≥n
2. **Machine Learning** - Predicciones autom√°ticas
3. **Aplicaci√≥n M√≥vil** - Interfaz responsive
4. **Integraci√≥n DB** - Conexi√≥n directa a bases de datos
5. **Dashboard Real-time** - M√©tricas en vivo

### Mejoras T√©cnicas
1. **Optimizaci√≥n de m√≥dulos** grandes
2. **Refactorizaci√≥n** de c√≥digo legacy
3. **Documentaci√≥n autom√°tica** con Sphinx
4. **CI/CD** completo
5. **Containerizaci√≥n** con Docker

---

**Para m√°s informaci√≥n, consulta el README principal o los ejemplos en la carpeta `examples/`.** 