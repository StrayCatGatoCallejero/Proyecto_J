# Arquitectura "Reloj Suizo" - Refactorizaci√≥n del Sistema de Estad√≠sticas

## üéØ Objetivo

Esta refactorizaci√≥n implementa el patr√≥n de arquitectura "Reloj Suizo" para mejorar la calidad, cohesi√≥n y mantenibilidad del c√≥digo estad√≠stico. Cada m√≥dulo tiene una responsabilidad √∫nica y bien definida, con interfaces claras y logging sistem√°tico.

## üèóÔ∏è Arquitectura Modular

### üìÅ Estructura de M√≥dulos

```
processing/
‚îú‚îÄ‚îÄ io.py           # Carga y validaci√≥n de archivos
‚îú‚îÄ‚îÄ stats.py        # An√°lisis estad√≠stico
‚îú‚îÄ‚îÄ visualization.py # Visualizaciones (matplotlib + plotly)
‚îú‚îÄ‚îÄ filters.py      # Filtrado y limpieza de datos
‚îú‚îÄ‚îÄ features.py     # Creaci√≥n y transformaci√≥n de features
‚îú‚îÄ‚îÄ logging.py      # Sistema de logging unificado
‚îî‚îÄ‚îÄ types.py        # Tipos y validaciones
```

### üîß Principios de Dise√±o

1. **Separaci√≥n de Responsabilidades**: Cada m√≥dulo tiene una funci√≥n espec√≠fica
2. **Interfaces Consistentes**: Todas las funciones siguen el mismo patr√≥n
3. **Logging Sistem√°tico**: Cada operaci√≥n se registra autom√°ticamente
4. **Validaci√≥n de Entrada**: Verificaci√≥n robusta de par√°metros
5. **Manejo de Errores**: Excepciones controladas y informativas

## üìä M√≥dulos Principales

### 1. I/O (`io.py`)

**Responsabilidades:**
- Carga de archivos (.sav, .dta, .csv, .xlsx)
- Validaci√≥n de integridad de datos
- Metadatos estructurados

**Funciones Principales:**
```python
# Cargar archivo con metadatos
df, metadata = cargar_archivo("datos.sav")

# Validar DataFrame
validation = validar_dataframe(df, metadata)

# Obtener informaci√≥n del archivo
info = obtener_info_archivo("datos.csv")
```

### 2. Estad√≠sticas (`stats.py`)

**Responsabilidades:**
- Estad√≠sticas descriptivas avanzadas
- Pruebas estad√≠sticas (normalidad, t-test, chi¬≤)
- An√°lisis de correlaciones y contingencia
- Regresi√≥n lineal y log√≠stica

**Funciones Principales:**
```python
# Estad√≠sticas descriptivas
stats = summary_statistics(df, ['edad', 'ingresos'])

# Correlaciones
corr = compute_correlations(df, ['edad', 'ingresos'], method='pearson')

# An√°lisis de contingencia
table, stats = contingency_analysis(df, 'educacion', 'genero')

# Pruebas de normalidad
normality = normality_test(df, 'edad')

# T-test independiente
t_result = t_test_independent(df, 'ingresos', 'genero')

# Regresi√≥n lineal
regression = linear_regression(df, 'satisfaccion', ['edad', 'ingresos'])
```

### 3. Visualizaci√≥n (`visualization.py`)

**Responsabilidades:**
- Visualizaciones est√°ticas con matplotlib
- Visualizaciones interactivas con plotly
- Generaci√≥n de gr√°ficos seg√∫n tipo de datos

**Funciones Principales:**
```python
# Visualizaciones est√°ticas (matplotlib)
fig = plot_histogram(df, 'edad', bins=20)
fig = plot_boxplot(df, 'ingresos', group_column='educacion')
fig = plot_scatter(df, 'edad', 'ingresos', color_column='genero')
fig = plot_heatmap(corr_matrix)
fig = plot_bar_chart(df, 'educacion', top_n=5)

# Visualizaciones interactivas (plotly)
fig = plotly_histogram(df, 'edad')
fig = plotly_heatmap(corr_matrix)
fig = plotly_scatter(df, 'edad', 'ingresos')
```

### 4. Filtros (`filters.py`)

**Responsabilidades:**
- Filtrado por condiciones simples y complejas
- Limpieza de datos (outliers, valores faltantes)
- Muestreo y selecci√≥n de datos

**Funciones Principales:**
```python
# Filtrado por condici√≥n
df_filtered = filter_by_condition(df, "edad > 25 and genero == 'M'")

# Filtrado por rango
df_filtered = filter_by_range(df, 'ingresos', min_val=1000, max_val=5000)

# Filtrado por valores
df_filtered = filter_by_values(df, 'region', ['Norte', 'Centro'])

# Eliminar outliers
df_clean = remove_outliers(df, 'ingresos', method='iqr')

# Manejar valores faltantes
df_clean = handle_missing_values(df, method='fill_median')

# Muestreo
df_sample = sample_data(df, fraction=0.5, random_state=42)
```

### 5. Features (`features.py`)

**Responsabilidades:**
- Creaci√≥n de features derivadas
- Codificaci√≥n de variables categ√≥ricas
- Escalado y normalizaci√≥n
- Selecci√≥n de features

**Funciones Principales:**
```python
# Features num√©ricas derivadas
df_features = create_numeric_features(df, ['edad', 'ingresos'])

# Codificaci√≥n categ√≥rica
df_features = encode_categorical(df, ['educacion'], method='label')

# Escalado
df_scaled = scale_features(df, ['edad', 'ingresos'], method='standard')

# Features de interacci√≥n
df_features = create_interaction_features(df, ['edad', 'ingresos'])

# Selecci√≥n de features
selected = select_features(df, 'target', method='correlation', n_features=10)

# Features temporales
df_features = create_time_features(df, 'fecha')

# Binning
df_features = create_binning_features(df, ['edad'], n_bins=5)
```

## üîÑ Patr√≥n de Uso

### Flujo T√≠pico de An√°lisis

```python
# 1. Cargar datos
df, metadata = cargar_archivo("datos.csv")
validation = validar_dataframe(df, metadata)

# 2. Limpiar datos
df_clean = handle_missing_values(df, method='fill_median')
df_clean = remove_outliers(df_clean, 'ingresos', method='iqr')
df_clean = drop_duplicates(df_clean)

# 3. An√°lisis estad√≠stico
stats = summary_statistics(df_clean, ['edad', 'ingresos'])
corr = compute_correlations(df_clean, ['edad', 'ingresos'])
normality = normality_test(df_clean, 'edad')

# 4. Crear features
df_features = create_numeric_features(df_clean, ['edad', 'ingresos'])
df_features = encode_categorical(df_features, ['educacion'], method='label')

# 5. Visualizar
fig = plot_histogram(df_clean, 'edad')
fig = plot_scatter(df_clean, 'edad', 'ingresos')
fig = plot_heatmap(corr)

# 6. An√°lisis avanzado
t_result = t_test_independent(df_clean, 'ingresos', 'genero')
regression = linear_regression(df_clean, 'satisfaccion', ['edad', 'ingresos'])
```

## üìà Logging y Trazabilidad

### Sistema de Logging Unificado

Cada funci√≥n registra autom√°ticamente:
- Par√°metros de entrada
- M√©tricas antes y despu√©s
- Tiempo de ejecuci√≥n
- Estado de √©xito/error
- Mensajes descriptivos

```python
# Ejemplo de log autom√°tico
log_action(
    function="summary_statistics",
    step="stats",
    parameters={"columns": ["edad", "ingresos"]},
    before_metrics={"n_rows": 1000},
    after_metrics={"n_variables": 2},
    status="success",
    message="Estad√≠sticas descriptivas calculadas",
    execution_time=0.15
)
```

### Configuraci√≥n de Logging

```python
# Configurar logging
from processing.logging import setup_logging
logger = setup_logging("config/config.yml")

# Obtener historial
history = logger.get_session_history()
summary = logger.get_summary_stats()
```

## üß™ Testing y Validaci√≥n

### Validaciones Autom√°ticas

- **Entrada**: Verificaci√≥n de tipos, rangos y existencia de columnas
- **Procesamiento**: Control de errores y excepciones
- **Salida**: Validaci√≥n de formatos y consistencia

### Ejemplos de Validaci√≥n

```python
# Validaci√≥n de entrada
if column not in df.columns:
    raise ValueError(f"La columna {column} no existe en el DataFrame")

if method not in valid_methods:
    raise ValueError(f"M√©todo debe ser uno de: {valid_methods}")

# Validaci√≥n de datos
if len(series) == 0:
    raise ValueError("No hay datos v√°lidos para procesar")
```

## üöÄ Ventajas de la Nueva Arquitectura

### 1. **Modularidad**
- Cada m√≥dulo tiene responsabilidades claras
- F√°cil mantenimiento y actualizaci√≥n
- Reutilizaci√≥n de componentes

### 2. **Consistencia**
- Interfaces uniformes en todos los m√≥dulos
- Patrones de uso similares
- Documentaci√≥n estandarizada

### 3. **Trazabilidad**
- Logging autom√°tico de todas las operaciones
- Auditor√≠a completa del pipeline
- Debugging facilitado

### 4. **Robustez**
- Validaci√≥n exhaustiva de entrada
- Manejo controlado de errores
- Recuperaci√≥n graceful de fallos

### 5. **Escalabilidad**
- F√°cil adici√≥n de nuevas funcionalidades
- Integraci√≥n con otros sistemas
- Paralelizaci√≥n de operaciones

## üìã Migraci√≥n desde C√≥digo Anterior

### Cambios Principales

1. **Funciones Renombradas**: Nombres m√°s descriptivos y consistentes
2. **Par√°metros Estandarizados**: Interfaces uniformes
3. **Logging Autom√°tico**: No requiere configuraci√≥n manual
4. **Validaci√≥n Robusta**: Verificaci√≥n autom√°tica de entrada
5. **Separaci√≥n de Responsabilidades**: Funciones m√°s espec√≠ficas

### Ejemplo de Migraci√≥n

**Antes:**
```python
# C√≥digo anterior (mezclado)
def analyze_data(df):
    # I/O, estad√≠sticas, visualizaci√≥n mezcladas
    pass
```

**Despu√©s:**
```python
# C√≥digo refactorizado (modular)
# 1. I/O
df, metadata = cargar_archivo("datos.csv")

# 2. Estad√≠sticas
stats = summary_statistics(df, ['edad', 'ingresos'])

# 3. Visualizaci√≥n
fig = plot_histogram(df, 'edad')
```

## üéØ Pr√≥ximos Pasos

1. **Documentaci√≥n**: Completar docstrings y ejemplos
2. **Testing**: Aumentar cobertura de pruebas
3. **Performance**: Optimizaci√≥n de operaciones cr√≠ticas
4. **Integraci√≥n**: Conectar con interfaces de usuario
5. **Extensi√≥n**: A√±adir nuevas funcionalidades estad√≠sticas

## üìö Recursos Adicionales

- `ejemplo_arquitectura_reloj_suizo.py`: Ejemplo completo de uso
- `processing/logging.py`: Documentaci√≥n del sistema de logging
- `tests/`: Suite de pruebas unitarias
- `config/config.yml`: Configuraci√≥n del sistema

---

**Nota**: Esta arquitectura sigue los principios SOLID y las mejores pr√°cticas de ingenier√≠a de software para crear un sistema robusto, mantenible y escalable. 