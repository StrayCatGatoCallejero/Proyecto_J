"""
Ejemplo Completo del Sistema de Logging JSON
============================================

Este ejemplo demuestra que el sistema de logging JSON est√° completamente
funcional y genera logs v√°lidos para cada paso del pipeline.
"""

import os
import sys
import json
import pandas as pd
import numpy as np
import tempfile
from datetime import datetime

# Agregar el directorio ra√≠z al path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from orchestrator.pipeline_orchestrator import PipelineOrchestrator
from processing.json_logging import LogLevel, LogCategory


def create_sample_data():
    """Crea datos de ejemplo para el test."""
    np.random.seed(42)
    
    data = {
        'edad': np.random.normal(35, 12, 50).astype(int),
        'ingresos': np.random.lognormal(10, 0.5, 50),
        'educacion': np.random.choice(['Primaria', 'Secundaria', 'Universitaria'], 50),
        'satisfaccion': np.random.randint(1, 11, 50),
        'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], 50)
    }
    
    return pd.DataFrame(data)


def create_config(temp_dir):
    """Crea configuraci√≥n para el test."""
    return {
        "config_path": "test_config",
        "logging": {
            "json_logging": {
                "enabled": True,
                "log_level": "DEBUG",
                "log_file": os.path.join(temp_dir, "pipeline_demo.json"),
                "max_file_size_mb": 5,
                "backup_count": 2,
                "rotation": {
                    "enabled": True,
                    "when": "midnight",
                    "interval": 1,
                    "backup_count": 2
                },
                "include_system_info": True,
                "include_session_id": True,
                "format": "json",
                "compression": False
            }
        },
        "data_processing": {
            "chunk_size": 1000,
            "parallel_processing": False,
            "memory_limit_mb": 256
        },
        "validation": {
            "strict_mode": False,
            "auto_fix": True,
            "report_errors": True
        },
        "visualization": {
            "theme": "default",
            "figure_size": [10, 6],
            "dpi": 100,
            "save_format": "png"
        }
    }


def main():
    """Funci√≥n principal que demuestra el sistema completo."""
    
    print("üöÄ DEMOSTRACI√ìN DEL SISTEMA DE LOGGING JSON")
    print("=" * 50)
    
    # Crear directorio temporal
    temp_dir = tempfile.mkdtemp()
    print(f"üìÅ Directorio temporal: {temp_dir}")
    
    try:
        # 1. Crear datos de ejemplo
        print("\nüìä 1. Creando datos de ejemplo...")
        sample_df = create_sample_data()
        sample_file = os.path.join(temp_dir, "test_data.csv")
        sample_df.to_csv(sample_file, index=False)
        print(f"   ‚úÖ Datos creados: {sample_df.shape} - Guardados en: {sample_file}")
        
        # 2. Crear configuraci√≥n
        print("\n‚öôÔ∏è  2. Configurando sistema...")
        config = create_config(temp_dir)
        print(f"   ‚úÖ Configuraci√≥n creada con logging JSON habilitado")
        
        # 3. Inicializar Pipeline Orchestrator
        print("\nüîß 3. Inicializando Pipeline Orchestrator...")
        orchestrator = PipelineOrchestrator(config)
        print(f"   ‚úÖ Session ID: {orchestrator.session_id}")
        
        # 4. Definir filtros y esquema
        print("\nüîç 4. Configurando filtros y validaciones...")
        filters = {
            "edad": {"min": 18, "max": 65},
            "educacion": {"values": ["Secundaria", "Universitaria"]}
        }
        
        schema = {
            "edad": {"type": "int", "min": 0, "max": 120},
            "ingresos": {"type": "float", "min": 0},
            "satisfaccion": {"type": "int", "min": 1, "max": 10}
        }
        print(f"   ‚úÖ Filtros y esquema configurados")
        
        # 5. Ejecutar pipeline completo
        print("\nüîÑ 5. Ejecutando pipeline completo...")
        print("   ‚è≥ Esto puede tomar unos segundos...")
        
        results = orchestrator.run_pipeline(
            path=sample_file,
            filters=filters,
            schema=schema
        )
        
        print("   ‚úÖ Pipeline ejecutado exitosamente!")
        
        # 6. Verificar resultados
        print("\nüìà 6. Resultados del pipeline:")
        print(f"   ‚Ä¢ Session ID: {results['session_id']}")
        print(f"   ‚Ä¢ Estado: {results['pipeline_status']}")
        print(f"   ‚Ä¢ Pasos completados: {results['pipeline_metrics']['completed_steps']}/{results['pipeline_metrics']['total_steps']}")
        print(f"   ‚Ä¢ Tiempo total: {results['pipeline_metrics']['total_execution_time']:.2f}s")
        print(f"   ‚Ä¢ Tasa de error: {results['pipeline_metrics']['error_rate']:.2%}")
        print(f"   ‚Ä¢ Forma de datos: {results['data_info']['shape']}")
        print(f"   ‚Ä¢ Uso de memoria: {results['data_info']['memory_usage_mb']:.2f} MB")
        
        # 7. Verificar archivo de log
        print("\nüìù 7. Verificando archivo de log...")
        log_file = config["logging"]["json_logging"]["log_file"]
        
        if os.path.exists(log_file):
            file_size = os.path.getsize(log_file) / 1024  # KB
            print(f"   ‚úÖ Archivo de log encontrado: {log_file}")
            print(f"   üìè Tama√±o: {file_size:.2f} KB")
            
            # Leer y analizar logs
            with open(log_file, 'r', encoding='utf-8') as f:
                log_lines = f.readlines()
            
            print(f"   üìä Total de entradas de log: {len(log_lines)}")
            
            # Analizar tipos de logs
            log_types = {}
            log_categories = {}
            log_steps = {}
            
            for line in log_lines:
                try:
                    log_entry = json.loads(line.strip())
                    
                    # Contar tipos
                    level = log_entry.get("level", "UNKNOWN")
                    log_types[level] = log_types.get(level, 0) + 1
                    
                    # Contar categor√≠as
                    category = log_entry.get("category", "UNKNOWN")
                    log_categories[category] = log_categories.get(category, 0) + 1
                    
                    # Contar pasos
                    step = log_entry.get("step", "UNKNOWN")
                    log_steps[step] = log_steps.get(step, 0) + 1
                    
                except json.JSONDecodeError as e:
                    print(f"   ‚ö†Ô∏è  Error en l√≠nea JSON: {e}")
            
            print(f"   üìä Tipos de logs: {log_types}")
            print(f"   üìä Categor√≠as: {log_categories}")
            print(f"   üìä Pasos: {log_steps}")
            
            # Verificar session ID consistente
            session_ids = set()
            for line in log_lines:
                log_entry = json.loads(line.strip())
                session_ids.add(log_entry.get("session_id"))
            
            if len(session_ids) == 1:
                print(f"   ‚úÖ Session ID consistente: {list(session_ids)[0]}")
            else:
                print(f"   ‚ö†Ô∏è  Session IDs inconsistentes: {session_ids}")
            
            # Mostrar ejemplo de log
            if log_lines:
                example_log = json.loads(log_lines[0].strip())
                print(f"   üìÑ Ejemplo de log:")
                print(f"      Timestamp: {example_log.get('timestamp')}")
                print(f"      Level: {example_log.get('level')}")
                print(f"      Message: {example_log.get('message')}")
                print(f"      Step: {example_log.get('step')}")
                print(f"      Category: {example_log.get('category')}")
            
        else:
            print(f"   ‚ùå Archivo de log no encontrado: {log_file}")
        
        # 8. Verificar estados de los pasos
        print("\nüìã 8. Estado de los pasos:")
        for step_name, step_info in results['step_statuses'].items():
            status_emoji = {
                'completed': '‚úÖ',
                'failed': '‚ùå',
                'running': 'üîÑ',
                'pending': '‚è≥',
                'skipped': '‚è≠Ô∏è'
            }.get(step_info['status'], '‚ùì')
            print(f"   {status_emoji} {step_name}: {step_info['status']}")
        
        # 9. Verificar m√©tricas detalladas
        print("\nüìä 9. M√©tricas detalladas del pipeline:")
        for step_name, metrics in orchestrator.pipeline_metrics.step_metrics.items():
            print(f"   üìà {step_name}:")
            print(f"      ‚Ä¢ Tiempo: {metrics.execution_time:.3f}s")
            print(f"      ‚Ä¢ Filas antes/despu√©s: {metrics.rows_before} ‚Üí {metrics.rows_after}")
            print(f"      ‚Ä¢ Memoria: {metrics.memory_before:.2f}MB ‚Üí {metrics.memory_after:.2f}MB")
            print(f"      ‚Ä¢ Delta memoria: {metrics.memory_delta:+.2f}MB")
        
        print("\nüéâ ¬°SISTEMA COMPLETAMENTE FUNCIONAL!")
        print("=" * 50)
        print("‚úÖ Pipeline Orchestrator funcionando correctamente")
        print("‚úÖ Logging JSON estructurado implementado")
        print("‚úÖ M√©tricas detalladas capturadas")
        print("‚úÖ Trazabilidad completa con session_id")
        print("‚úÖ Archivo de log generado y validado")
        
        print(f"\nüìÅ Archivos generados:")
        print(f"   ‚Ä¢ {sample_file}")
        print(f"   ‚Ä¢ {log_file}")
        
        print(f"\nüîç Pr√≥ximos pasos:")
        print(f"   1. Revisa el archivo de log: {log_file}")
        print(f"   2. Analiza las m√©tricas de rendimiento")
        print(f"   3. Integra con sistemas de monitoreo (ELK, Datadog)")
        print(f"   4. Personaliza la configuraci√≥n seg√∫n tus necesidades")
        
        return True
        
    except Exception as e:
        print(f"\nüí• Error en la demostraci√≥n: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # Limpiar archivos temporales
        try:
            import shutil
            shutil.rmtree(temp_dir)
            print(f"\nüßπ Directorio temporal limpiado: {temp_dir}")
        except:
            pass


if __name__ == "__main__":
    success = main()
    if success:
        print("\n‚úÖ Demostraci√≥n completada exitosamente")
    else:
        print("\n‚ùå La demostraci√≥n fall√≥")
        sys.exit(1) 