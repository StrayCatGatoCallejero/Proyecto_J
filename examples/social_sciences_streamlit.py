"""
AplicaciÃ³n Streamlit para AnÃ¡lisis de Ciencias Sociales
======================================================

Interfaz web para el anÃ¡lisis especializado de datos de ciencias sociales,
encuestas y estudios demogrÃ¡ficos.
"""

import streamlit as st
import pandas as pd
import numpy as np
from typing import Dict, List, Any
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
import matplotlib.pyplot as plt

from social_sciences_analyzer import SocialSciencesAnalyzer, analyze_survey_data

# ConfiguraciÃ³n de la pÃ¡gina
    st.set_page_config(
    page_title="AnÃ¡lisis de Ciencias Sociales", page_icon="ğŸ“", layout="wide"
    )
    
# TÃ­tulo principal
st.title("ğŸ“ Analizador Avanzado de Datos de Ciencias Sociales")
    st.markdown("---")

# Inicializar session state
if "analyzer" not in st.session_state:
    st.session_state.analyzer = SocialSciencesAnalyzer()
if "analysis_results" not in st.session_state:
    st.session_state.analysis_results = None
if "uploaded_data" not in st.session_state:
    st.session_state.uploaded_data = None


def main():
    """FunciÃ³n principal de la aplicaciÃ³n."""

    # Sidebar para navegaciÃ³n
    st.sidebar.title("ğŸ“Š NavegaciÃ³n")
    page = st.sidebar.selectbox(
        "Selecciona la secciÃ³n:",
        [
            "ğŸ“ Cargar Datos",
            "ğŸ” AnÃ¡lisis SemÃ¡ntico",
            "ğŸ“ Escalas Likert",
            "ğŸ”„ NormalizaciÃ³n",
            "âœ… ValidaciÃ³n",
            "ğŸ“ˆ Visualizaciones",
            "ğŸ“¤ Exportar",
        ],
    )

    if page == "ğŸ“ Cargar Datos":
        load_data_page()
    elif page == "ğŸ” AnÃ¡lisis SemÃ¡ntico":
        semantic_analysis_page()
    elif page == "ğŸ“ Escalas Likert":
        likert_scales_page()
    elif page == "ğŸ”„ NormalizaciÃ³n":
        normalization_page()
    elif page == "âœ… ValidaciÃ³n":
        validation_page()
    elif page == "ğŸ“ˆ Visualizaciones":
        visualizations_page()
    elif page == "ğŸ“¤ Exportar":
        export_page()


def load_data_page():
    """PÃ¡gina para cargar datos."""
    st.header("ğŸ“ Cargar Datos")
    
    uploaded_file = st.file_uploader(
        "Selecciona un archivo de datos:",
        type=["csv", "xlsx", "xls"],
        help="Soporta archivos CSV, Excel (.xlsx, .xls)",
    )
    
    if uploaded_file is not None:
        try:
            # Cargar datos segÃºn el tipo de archivo
            if uploaded_file.name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.session_state.uploaded_data = df

            # Mostrar informaciÃ³n bÃ¡sica
            st.success(
                f"âœ… Datos cargados exitosamente: {df.shape[0]} filas, {df.shape[1]} columnas"
            )

            # Resumen de datos
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("Filas", df.shape[0])
            with col2:
                st.metric("Columnas", df.shape[1])
            with col3:
                st.metric("Valores faltantes", df.isnull().sum().sum())

            # Mostrar primeras filas
            st.subheader("ğŸ“‹ Vista previa de los datos")
            st.dataframe(df.head())

            # InformaciÃ³n de tipos de datos
            st.subheader("ğŸ” Tipos de datos")
            dtype_info = pd.DataFrame(
                {
                    "Columna": df.columns,
                    "Tipo": df.dtypes,
                    "Valores Ãºnicos": df.nunique(),
                    "Valores faltantes": df.isnull().sum(),
                }
            )
            st.dataframe(dtype_info)

        except Exception as e:
            st.error(f"âŒ Error al cargar el archivo: {str(e)}")


def semantic_analysis_page():
    """PÃ¡gina de anÃ¡lisis semÃ¡ntico."""
    st.header("ğŸ” AnÃ¡lisis SemÃ¡ntico")

    if st.session_state.uploaded_data is None:
        st.warning("âš ï¸ Por favor carga datos primero en la secciÃ³n 'Cargar Datos'")
        return

    df = st.session_state.uploaded_data

    # ConfiguraciÃ³n del anÃ¡lisis
    st.subheader("âš™ï¸ ConfiguraciÃ³n")
    confidence_threshold = st.slider(
        "Umbral de confianza para clasificaciÃ³n:",
        min_value=0.5,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="Confianza mÃ­nima para clasificar una columna",
    )

    if st.button("ğŸ” Ejecutar AnÃ¡lisis SemÃ¡ntico"):
        with st.spinner("Analizando datos..."):
            # Realizar anÃ¡lisis semÃ¡ntico
            results = st.session_state.analyzer.analyze_survey_data(df)
            st.session_state.analysis_results = results

            # Mostrar resultados
            st.success("âœ… AnÃ¡lisis semÃ¡ntico completado")

            # ClasificaciÃ³n semÃ¡ntica
            st.subheader("ğŸ“Š ClasificaciÃ³n SemÃ¡ntica")
            classification = results["semantic_classification"]

            # Crear DataFrame para mostrar resultados
            classification_df = pd.DataFrame(
                [
                    {"Columna": col, "ClasificaciÃ³n": cls}
                    for col, cls in classification.items()
                ]
            )

            st.dataframe(classification_df)

            # EstadÃ­sticas de clasificaciÃ³n
            st.subheader("ğŸ“ˆ EstadÃ­sticas de ClasificaciÃ³n")
            cls_counts = pd.Series(classification.values()).value_counts()

    fig = px.bar(
                x=cls_counts.index,
                y=cls_counts.values,
                title="DistribuciÃ³n de Clasificaciones SemÃ¡nticas",
                labels={"x": "Tipo de ClasificaciÃ³n", "y": "Cantidad"},
            )
            st.plotly_chart(fig)


def likert_scales_page():
    """PÃ¡gina de detecciÃ³n de escalas Likert."""
    st.header("ğŸ“ DetecciÃ³n de Escalas Likert")

    if st.session_state.analysis_results is None:
        st.warning("âš ï¸ Por favor ejecuta el anÃ¡lisis semÃ¡ntico primero")
        return
    
    results = st.session_state.analysis_results
    likert_scales = results.get("likert_scales", {})

    if not likert_scales:
        st.info("â„¹ï¸ No se detectaron escalas Likert en los datos")
        return
    
    st.success(f"âœ… Se detectaron {len(likert_scales)} columnas con escalas Likert")

    # Mostrar escalas detectadas
    for col, scales in likert_scales.items():
        with st.expander(f"ğŸ“ {col} - Escalas detectadas"):
            st.write("**Escalas encontradas:**")
            for scale in scales:
                st.write(f"â€¢ {scale}")

            # Mostrar distribuciÃ³n de valores
            df = st.session_state.uploaded_data
            if col in df.columns:
                value_counts = df[col].value_counts()
                    
                    fig = px.bar(
                    x=value_counts.index,
                    y=value_counts.values,
                    title=f"DistribuciÃ³n de valores en {col}",
                    labels={"x": "Valor", "y": "Frecuencia"},
                )
                st.plotly_chart(fig)


def normalization_page():
    """PÃ¡gina de normalizaciÃ³n de categorÃ­as."""
    st.header("ğŸ”„ NormalizaciÃ³n de CategorÃ­as")

    if st.session_state.analysis_results is None:
        st.warning("âš ï¸ Por favor ejecuta el anÃ¡lisis semÃ¡ntico primero")
        return
    
    results = st.session_state.analysis_results
    normalization = results.get("normalized_categories", {})

    if not normalization:
        st.info("â„¹ï¸ No se encontraron categorÃ­as para normalizar")
        return

    st.success(
        f"âœ… Se encontraron {len(normalization)} columnas con categorÃ­as para normalizar"
    )

    # ConfiguraciÃ³n de normalizaciÃ³n
    st.subheader("âš™ï¸ ConfiguraciÃ³n de NormalizaciÃ³n")
    similarity_threshold = st.slider(
        "Umbral de similitud:",
        min_value=0.5,
        max_value=1.0,
        value=0.8,
        step=0.1,
        help="Umbral de similitud para agrupar categorÃ­as",
    )

    # Mostrar mapeos de normalizaciÃ³n
    for col, mapping in normalization.items():
        with st.expander(f"ğŸ”„ {col} - Mapeos de normalizaciÃ³n"):
            st.write("**Mapeos encontrados:**")
            for original, normalized in mapping.items():
                st.write(f"â€¢ '{original}' â†’ '{normalized}'")


def validation_page():
    """PÃ¡gina de validaciÃ³n de consistencia."""
    st.header("âœ… ValidaciÃ³n de Consistencia")

    if st.session_state.analysis_results is None:
        st.warning("âš ï¸ Por favor ejecuta el anÃ¡lisis semÃ¡ntico primero")
        return

    results = st.session_state.analysis_results
    inconsistencies = results.get("consistency_validation", {})

    if not inconsistencies:
        st.success("âœ… No se encontraron inconsistencias en los datos")
        return

    st.warning(f"âš ï¸ Se encontraron {len(inconsistencies)} tipos de inconsistencias")

    # Mostrar inconsistencias
    for issue_type, issues in inconsistencies.items():
        with st.expander(f"âŒ {issue_type}"):
            st.write(f"**Problemas encontrados ({len(issues)}):**")
            for issue in issues:
                st.write(f"â€¢ {issue}")


def visualizations_page():
    """PÃ¡gina de visualizaciones sugeridas."""
    st.header("ğŸ“ˆ Visualizaciones Sugeridas")

    if st.session_state.analysis_results is None:
        st.warning("âš ï¸ Por favor ejecuta el anÃ¡lisis semÃ¡ntico primero")
        return

            results = st.session_state.analysis_results
    suggestions = results.get("visualization_suggestions", {})

    if not suggestions:
        st.info("â„¹ï¸ No hay sugerencias de visualizaciÃ³n disponibles")
        return

    st.success(f"âœ… Se generaron sugerencias para {len(suggestions)} columnas")

    # Mostrar sugerencias por columna
    for col, viz_suggestions in suggestions.items():
        with st.expander(f"ğŸ“Š {col} - Visualizaciones sugeridas"):
            st.write("**Visualizaciones recomendadas:**")
            for viz in viz_suggestions:
                st.write(f"â€¢ {viz}")

            # Crear visualizaciÃ³n de ejemplo
            df = st.session_state.uploaded_data
            if col in df.columns:
                try:
                    if viz_suggestions and "histogram" in viz_suggestions:
                        fig = px.histogram(df, x=col, title=f"Histograma de {col}")
                        st.plotly_chart(fig)
                    elif viz_suggestions and "bar" in viz_suggestions:
                        value_counts = df[col].value_counts()
                        fig = px.bar(
                            x=value_counts.index,
                            y=value_counts.values,
                            title=f"DistribuciÃ³n de {col}",
                        )
                        st.plotly_chart(fig)
                except Exception as e:
                    st.warning(f"No se pudo crear visualizaciÃ³n: {str(e)}")


def export_page():
    """PÃ¡gina de exportaciÃ³n de resultados."""
    st.header("ğŸ“¤ Exportar Resultados")

    if st.session_state.analysis_results is None:
        st.warning("âš ï¸ No hay resultados para exportar")
        return

    results = st.session_state.analysis_results

    # Opciones de exportaciÃ³n
    st.subheader("ğŸ“‹ Seleccionar datos para exportar")

    export_options = st.multiselect(
        "Selecciona quÃ© exportar:",
        [
            "ClasificaciÃ³n SemÃ¡ntica",
            "Escalas Likert",
            "NormalizaciÃ³n",
            "ValidaciÃ³n de Consistencia",
            "Sugerencias de VisualizaciÃ³n",
        ],
        default=["ClasificaciÃ³n SemÃ¡ntica"],
    )

    if st.button("ğŸ“¤ Exportar Resultados"):
        # Crear DataFrame con resultados seleccionados
        export_data = {}

        if "ClasificaciÃ³n SemÃ¡ntica" in export_options:
            classification = results.get("semantic_classification", {})
            export_data["clasificacion_semantica"] = pd.DataFrame(
                [
                    {"columna": col, "clasificacion": cls}
                    for col, cls in classification.items()
                ]
            )

        if "Escalas Likert" in export_options:
            likert_scales = results.get("likert_scales", {})
            likert_data = []
            for col, scales in likert_scales.items():
                for scale in scales:
                    likert_data.append({"columna": col, "escala": scale})
            if likert_data:
                export_data["escalas_likert"] = pd.DataFrame(likert_data)

        # Exportar como CSV
        if export_data:
            csv_data = pd.concat(export_data.values(), keys=export_data.keys(), axis=0)
                st.download_button(
                label="ğŸ“„ Descargar CSV",
                data=csv_data.to_csv(index=False),
                file_name="analisis_ciencias_sociales.csv",
                mime="text/csv",
            )

            st.success("âœ… Resultados listos para descargar")


if __name__ == "__main__":
    main()
