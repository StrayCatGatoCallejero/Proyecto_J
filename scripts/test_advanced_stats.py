"""
Script de Prueba: An√°lisis Estad√≠stico Avanzado
==============================================

Demuestra el sistema completo de an√°lisis estad√≠stico avanzado
con datos sint√©ticos de ciencias sociales.
"""

import pandas as pd
import numpy as np
from datetime import datetime
import sys
import os

# Agregar el directorio ra√≠z al path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from orchestrator.pipeline_orchestrator import PipelineOrchestrator
from processing.stats import (
    summary_statistics_advanced,
    recommend_statistical_tests,
    linear_regression_analysis,
    suggest_analysis_for_ui,
    compute_correlations
)

def create_synthetic_social_data(n_samples=1000):
    """Crea datos sint√©ticos de ciencias sociales para pruebas."""
    np.random.seed(42)
    
    # Datos demogr√°ficos
    edad = np.random.normal(35, 12, n_samples)
    edad = np.clip(edad, 18, 80)
    
    genero = np.random.choice(['Masculino', 'Femenino', 'No binario'], n_samples, p=[0.48, 0.48, 0.04])
    
    educacion = np.random.choice([
        'Sin educaci√≥n', 'Primaria', 'Secundaria', 'T√©cnica', 'Universitaria', 'Postgrado'
    ], n_samples, p=[0.05, 0.15, 0.30, 0.20, 0.25, 0.05])
    
    # Datos socioecon√≥micos
    ingresos = np.random.lognormal(10.5, 0.8, n_samples)  # Distribuci√≥n log-normal t√≠pica de ingresos
    ingresos = np.clip(ingresos, 200000, 5000000)
    
    # Correlaci√≥n entre educaci√≥n e ingresos
    educacion_numerica = pd.Categorical(educacion).codes
    ingresos = ingresos * (1 + 0.3 * educacion_numerica + np.random.normal(0, 0.2, n_samples))
    
    # Datos de opini√≥n (escalas Likert)
    satisfaccion_vida = np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.1, 0.2, 0.3, 0.3, 0.1])
    confianza_gobierno = np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.3, 0.3, 0.2, 0.15, 0.05])
    
    # Correlaci√≥n entre satisfacci√≥n y confianza
    confianza_gobierno = np.clip(confianza_gobierno + np.random.normal(0, 0.5, n_samples), 1, 5).astype(int)
    
    # Datos geogr√°ficos
    region = np.random.choice([
        'Metropolitana', 'Valpara√≠so', 'O\'Higgins', 'Maule', 'Biob√≠o', 'Araucan√≠a'
    ], n_samples, p=[0.4, 0.15, 0.1, 0.1, 0.15, 0.1])
    
    # Crear DataFrame
    df = pd.DataFrame({
        'edad': edad,
        'genero': genero,
        'educacion': educacion,
        'ingresos': ingresos,
        'satisfaccion_vida': satisfaccion_vida,
        'confianza_gobierno': confianza_gobierno,
        'region': region
    })
    
    return df

def create_metadata():
    """Crea metadata sem√°ntica para los datos."""
    return {
        'edad': {
            'category': 'demographic',
            'unit': 'a√±os',
            'type': 'numeric',
            'description': 'Edad del encuestado'
        },
        'genero': {
            'category': 'demographic',
            'type': 'categorical',
            'description': 'Identidad de g√©nero'
        },
        'educacion': {
            'category': 'demographic',
            'type': 'categorical',
            'description': 'Nivel educativo alcanzado'
        },
        'ingresos': {
            'category': 'socioeconomic',
            'unit': 'CLP',
            'type': 'numeric',
            'description': 'Ingresos mensuales'
        },
        'satisfaccion_vida': {
            'category': 'opinion',
            'type': 'likert',
            'scale': '1-5',
            'description': 'Satisfacci√≥n con la vida'
        },
        'confianza_gobierno': {
            'category': 'opinion',
            'type': 'likert',
            'scale': '1-5',
            'description': 'Confianza en el gobierno'
        },
        'region': {
            'category': 'geographic',
            'type': 'categorical',
            'description': 'Regi√≥n de residencia'
        }
    }

def test_advanced_statistics():
    """Prueba el an√°lisis estad√≠stico avanzado."""
    print("üî¨ Iniciando prueba de an√°lisis estad√≠stico avanzado...")
    print("=" * 60)
    
    # 1. Crear datos sint√©ticos
    print("üìä Creando datos sint√©ticos de ciencias sociales...")
    df = create_synthetic_social_data(1000)
    metadata = create_metadata()
    
    print(f"‚úÖ Datos creados: {len(df)} filas, {len(df.columns)} columnas")
    print(f"   Columnas: {list(df.columns)}")
    print()
    
    # 2. Estad√≠sticas descriptivas avanzadas
    print("üìà Calculando estad√≠sticas descriptivas avanzadas...")
    try:
        advanced_stats = summary_statistics_advanced(df, metadata)
        print(f"‚úÖ Estad√≠sticas calculadas para {len(advanced_stats['column_statistics'])} variables")
        
        # Mostrar resumen
        summary = advanced_stats['summary']
        print(f"   üìä Variables analizadas: {summary['total_columns_analyzed']}")
        print(f"   ‚ö†Ô∏è Outliers totales: {summary['total_outliers']}")
        print(f"   üìâ Variables no normales: {summary['non_normal_variables']}")
        print()
        
        # Mostrar ejemplo de estad√≠sticas para una variable
        if 'ingresos' in advanced_stats['column_statistics']:
            ingresos_stats = advanced_stats['column_statistics']['ingresos']
            print("üí∞ Ejemplo - Estad√≠sticas de ingresos:")
            basic = ingresos_stats['basic_stats']
            print(f"   Media: ${basic['mean']:,.0f} CLP")
            print(f"   Mediana: ${basic['median']:,.0f} CLP")
            print(f"   Desv. Est.: ${basic['std']:,.0f} CLP")
            print(f"   Outliers: {ingresos_stats['outlier_stats']['outliers_count']} ({ingresos_stats['outlier_stats']['outliers_percentage']:.1f}%)")
            print()
        
    except Exception as e:
        print(f"‚ùå Error en estad√≠sticas descriptivas: {str(e)}")
        return
    
    # 3. Recomendaciones de pruebas estad√≠sticas
    print("üîç Generando recomendaciones de pruebas estad√≠sticas...")
    try:
        test_recommendations = recommend_statistical_tests(df, metadata, metadata)
        print(f"‚úÖ {len(test_recommendations)} recomendaciones generadas")
        
        # Mostrar algunas recomendaciones
        for i, rec in enumerate(test_recommendations[:3]):
            print(f"   {i+1}. {rec['test_name']}: {rec['rationale']}")
        print()
        
    except Exception as e:
        print(f"‚ùå Error en recomendaciones: {str(e)}")
    
    # 4. An√°lisis de correlaciones
    print("üîó Calculando correlaciones...")
    try:
        correlations = compute_correlations(df)
        print(f"‚úÖ Correlaciones calculadas")
        
        sig_corrs = correlations.get('significant_correlations', [])
        print(f"   üìä Correlaciones significativas: {len(sig_corrs)}")
        
        if sig_corrs:
            print("   Top 3 correlaciones:")
            for i, corr in enumerate(sig_corrs[:3]):
                print(f"      {i+1}. {corr['variable1']} ‚Üî {corr['variable2']}: r={corr['correlation']:.3f} (p={corr['p_value']:.3f})")
        print()
        
    except Exception as e:
        print(f"‚ùå Error en correlaciones: {str(e)}")
    
    # 5. Sugerencias para UI
    print("üí° Generando sugerencias de an√°lisis...")
    try:
        ui_suggestions = suggest_analysis_for_ui(df, advanced_stats, correlations, metadata)
        print(f"‚úÖ {len(ui_suggestions)} sugerencias generadas")
        
        for i, suggestion in enumerate(ui_suggestions[:2]):
            print(f"   {i+1}. {suggestion['type']}: {suggestion['message'][:100]}...")
        print()
        
    except Exception as e:
        print(f"‚ùå Error en sugerencias: {str(e)}")
    
    # 6. An√°lisis de regresi√≥n
    print("üìà Realizando an√°lisis de regresi√≥n...")
    try:
        # Regresi√≥n: ingresos ~ edad + educaci√≥n
        regression_result = linear_regression_analysis(
            df, 'ingresos', ['edad'], metadata
        )
        print(f"‚úÖ Modelo de regresi√≥n creado")
        print(f"   R¬≤: {regression_result['r_squared']:.3f}")
        print(f"   RMSE: {regression_result['rmse']:,.0f}")
        print(f"   Interpretaci√≥n: {regression_result['semantic_interpretation']['model_fit']}")
        print()
        
    except Exception as e:
        print(f"‚ùå Error en regresi√≥n: {str(e)}")
    
    # 7. Prueba del orquestador completo
    print("üéØ Probando orquestador completo...")
    try:
        orchestrator = PipelineOrchestrator()
        
        # Simular carga de datos
        print("   üìÅ Simulando carga de datos...")
        orchestrator.session_data.df = df
        orchestrator.session_data.metadata = metadata
        orchestrator.session_data.semantic_classification = metadata
        
        # Ejecutar an√°lisis estad√≠stico
        print("   üìä Ejecutando an√°lisis estad√≠stico...")
        result = orchestrator.run_step('statistical_analysis')
        
        if result['status'] == 'success':
            print("   ‚úÖ An√°lisis estad√≠stico completado exitosamente")
            stats_data = result['result']
            print(f"      - Estad√≠sticas: {len(stats_data.get('descriptive_statistics', {}).get('column_statistics', {}))} variables")
            print(f"      - Recomendaciones: {len(stats_data.get('test_recommendations', []))} pruebas")
            print(f"      - Sugerencias: {len(stats_data.get('ui_suggestions', []))} sugerencias")
        else:
            print(f"   ‚ùå Error en orquestador: {result['error']}")
        
    except Exception as e:
        print(f"‚ùå Error en orquestador: {str(e)}")
    
    print("=" * 60)
    print("üéâ Prueba de an√°lisis estad√≠stico avanzado completada!")
    print("üìã Resumen:")
    print("   ‚úÖ Datos sint√©ticos creados")
    print("   ‚úÖ Estad√≠sticas descriptivas avanzadas")
    print("   ‚úÖ Recomendaciones de pruebas")
    print("   ‚úÖ An√°lisis de correlaciones")
    print("   ‚úÖ Sugerencias de an√°lisis")
    print("   ‚úÖ Modelos de regresi√≥n")
    print("   ‚úÖ Orquestador integrado")
    print()
    print("üöÄ El sistema est√° listo para an√°lisis de datos de ciencias sociales!")

if __name__ == "__main__":
    test_advanced_statistics() 